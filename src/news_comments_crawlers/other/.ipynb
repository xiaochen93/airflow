{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522f19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver    \n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "from nltk import word_tokenize, Text, FreqDist\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "import pathlib\n",
    "from newspaper import Article\n",
    "from urllib.parse import urlparse\n",
    "# importing itertools for accumulate()\n",
    "import itertools\n",
    "# importing functools for reduce()\n",
    "import functools\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import json\n",
    "import praw\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e7e5c-63eb-4bc1-a006-cad43e5a9fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5858186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"sAagBNvoj_godvd7yHezMg\" \n",
    "client_secret = \"cifjzGjeWkDhX1XA2zuTGW-X_vPevg\"\n",
    "user_agent = \"testing_api\"\n",
    "username = \"xiaochen93\"\n",
    "password = \"Xiaopangzi93!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bc275",
   "metadata": {},
   "source": [
    "# Praw Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "54318cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xiaochen93\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    reddit = praw.Reddit(client_id = client_id,\n",
    "                         client_secret = client_secret,\n",
    "                         user_agent = user_agent,\n",
    "                         username = username,\n",
    "                         password = password\n",
    "                        )\n",
    "    print(reddit.user.me())\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a24ec426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STR_FIELD', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chunk', '_comments_by_id', '_fetch', '_fetch_data', '_fetch_info', '_fetched', '_kind', '_reddit', '_reset_attributes', '_safely_add_arguments', '_url_parts', '_vote', 'all_awardings', 'allow_live_comments', 'approved_at_utc', 'approved_by', 'archived', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'award', 'awarders', 'banned_at_utc', 'banned_by', 'can_gild', 'can_mod_post', 'category', 'clear_vote', 'clicked', 'comment_limit', 'comment_sort', 'comments', 'content_categories', 'contest_mode', 'created', 'created_utc', 'crosspost', 'delete', 'disable_inbox_replies', 'discussion_type', 'distinguished', 'domain', 'downs', 'downvote', 'duplicates', 'edit', 'edited', 'enable_inbox_replies', 'flair', 'fullname', 'gild', 'gilded', 'gildings', 'hidden', 'hide', 'hide_score', 'id', 'id_from_url', 'is_created_from_ads_ui', 'is_crosspostable', 'is_meta', 'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video', 'likes', 'link_flair_background_color', 'link_flair_css_class', 'link_flair_richtext', 'link_flair_template_id', 'link_flair_text', 'link_flair_text_color', 'link_flair_type', 'locked', 'mark_visited', 'media', 'media_embed', 'media_only', 'mod', 'mod_note', 'mod_reason_by', 'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_comments', 'num_crossposts', 'num_reports', 'over_18', 'parent_whitelist_status', 'parse', 'permalink', 'pinned', 'post_hint', 'preview', 'pwls', 'quarantine', 'removal_reason', 'removed_by', 'removed_by_category', 'reply', 'report', 'report_reasons', 'save', 'saved', 'score', 'secure_media', 'secure_media_embed', 'selftext', 'selftext_html', 'send_replies', 'shortlink', 'spoiler', 'stickied', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_subscribers', 'subreddit_type', 'suggested_sort', 'thumbnail', 'thumbnail_height', 'thumbnail_width', 'title', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'unhide', 'unsave', 'ups', 'upvote', 'upvote_ratio', 'url', 'url_overridden_by_dest', 'user_reports', 'view_count', 'visited', 'whitelist_status', 'wls']\n",
      "[Meme Monday] Singaporean Lo-Fi Girl\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('singapore')\n",
    "top = subreddit.top(limit=10)\n",
    "\n",
    "for submission in top:\n",
    "    print(dir(submission))\n",
    "    print(submission.title)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6a6502b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"beats\" to study to indeed\n",
      "['MISSING_COMMENT_MESSAGE', 'STR_FIELD', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_extract_submission_id', '_fetch', '_fetch_data', '_fetch_info', '_fetched', '_kind', '_reddit', '_replies', '_reset_attributes', '_safely_add_arguments', '_submission', '_url_parts', '_vote', 'all_awardings', 'approved_at_utc', 'approved_by', 'archived', 'associated_award', 'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', 'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type', 'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'award', 'awarders', 'banned_at_utc', 'banned_by', 'block', 'body', 'body_html', 'can_gild', 'can_mod_post', 'clear_vote', 'collapse', 'collapsed', 'collapsed_because_crowd_control', 'collapsed_reason', 'collapsed_reason_code', 'comment_type', 'controversiality', 'created', 'created_utc', 'delete', 'depth', 'disable_inbox_replies', 'distinguished', 'downs', 'downvote', 'edit', 'edited', 'enable_inbox_replies', 'fullname', 'gild', 'gilded', 'gildings', 'id', 'id_from_url', 'is_root', 'is_submitter', 'likes', 'link_id', 'locked', 'mark_read', 'mark_unread', 'mod', 'mod_note', 'mod_reason_by', 'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_reports', 'parent', 'parent_id', 'parse', 'permalink', 'refresh', 'removal_reason', 'replies', 'reply', 'report', 'report_reasons', 'save', 'saved', 'score', 'score_hidden', 'send_replies', 'stickied', 'submission', 'subreddit', 'subreddit_id', 'subreddit_name_prefixed', 'subreddit_type', 'top_awarded_type', 'total_awards_received', 'treatment_tags', 'unblock_subreddit', 'uncollapse', 'unrepliable_reason', 'unsave', 'ups', 'upvote', 'user_reports']\n"
     ]
    }
   ],
   "source": [
    "for comment in submission.comments:\n",
    "    print(comment.body)\n",
    "    print(dir(comment))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec038a",
   "metadata": {},
   "source": [
    "# Selenium Web Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b57df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.example.test\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "domain = urlparse('http://www.example.test/foo/bar').netloc\n",
    "print(domain) # --> www.example.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fea54902",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://old.reddit.com/r/singapore/top/\"\n",
    "\n",
    "out = []\n",
    "\n",
    "def RedditSearch(url,label):\n",
    "    out = []\n",
    "    #initalise crawler option(s)\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"detach\", True)\n",
    "    options.add_argument('headless')\n",
    "    ROOT_DIR = pathlib.Path().absolute()\n",
    "    print(ROOT_DIR)\n",
    "    driver = webdriver.Chrome(executable_path=(str(ROOT_DIR)+\"/chromedriver\"), options=options)\n",
    "    driver.set_window_size(1120, 1000)  \n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #1. click to the time series\n",
    "    xpath_dropdown = \"//div[contains(@class,'dropdown lightdrop')]\"\n",
    "    xpath_choices = \"//DIV[contains(@class,'drop-choices')]//A[contains(@class,'choice')]\"\n",
    "    #1. allocate the dropdown menu and click the timeseries\n",
    "    timeseries = getDropdownChoices(driver,xpath_dropdown, xpath_choices)\n",
    "    timeseries = [choice for choice in timeseries if choice.text == label]\n",
    "    \n",
    "    if not timeseries == []:\n",
    "        timeseries[0].click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #3. loop and retrieve items on the page.\n",
    "    searching = True\n",
    "    noOfDocs = 0\n",
    "    while searching:\n",
    "        #2. load main page and pick relative items\n",
    "        xpath_main_page_items = \"//div[contains(@class,'thing id-t3')  and .//SPAN/@title='News']\"\n",
    "        \n",
    "        items = getTableItems(driver, xpath_main_page_items)\n",
    "    \n",
    "        for item in items:\n",
    "            # get the post id\n",
    "            try:\n",
    "                post_id = item.get_property(\"id\")\n",
    "            except NoSuchElementException:\n",
    "                print('-- post id not found')\n",
    "                post_id = \"\"\n",
    "            # get the news title\n",
    "            try:\n",
    "                title = item.find_element(\"xpath\",\".//descendant-or-self::A[contains(@class,'title may-blank')]\").text\n",
    "            except NoSuchElementException:\n",
    "                title = \"\"\n",
    "            # get the news URL\n",
    "            try:\n",
    "                title_url = item.find_element(\"xpath\",\".//descendant-or-self::A[contains(@class,'title may-blank')]\").get_property('href')\n",
    "            except NoSuchElementException:\n",
    "                title_url = \"\"\n",
    "            # get the datetime\n",
    "            try:\n",
    "                datetime  = item.find_element(\"xpath\", \".//descendant-or-self::p[contains(@class, 'tagline')]/time\").get_attribute('datetime')\n",
    "            except NoSuchElementException:\n",
    "                datetime = \"\"\n",
    "            # get the domain name\n",
    "            try:\n",
    "                domain = item.find_element(\"xpath\", \".//descendant-or-self::SPAN[contains(@class, 'domain')]\").text\n",
    "            except NoSuchElementException:\n",
    "                domain = \"\"\n",
    "\n",
    "            domain = urlparse(title_url).netloc\n",
    "            # get the news score\n",
    "            try:\n",
    "                scores = item.find_element(\"xpath\", \".//descendant-or-self::div[contains(@class, 'score unvoted')]\").text\n",
    "            except NoSuchElementException:\n",
    "                scores = \"\"\n",
    "            # get the no of comments\n",
    "            try:\n",
    "                no_of_cmts = item.find_element(\"xpath\", \".//descendant-or-self::li[contains(@class,'first')]/a\").text.split()[0]\n",
    "            except NoSuchElementException:\n",
    "                no_of_cmts = \"0\"\n",
    "            # get the comment URL\n",
    "            try:\n",
    "                cmt_url = item.find_element(\"xpath\", \".//descendant-or-self::li[contains(@class,'first')]/a\").get_property('href')\n",
    "            except NosuchElementException:\n",
    "                cmt_url = \"\"\n",
    "            # get the article content\n",
    "            content = getNewsContentByArticle(Article, title_url)\n",
    "\n",
    "            if content == \"\" or \"reddit\" in title_url:\n",
    "                out_dict = getNewsContentByGoogle(title)\n",
    "                content = out_dict['content']\n",
    "                domain = out_dict['domain']\n",
    "\n",
    "            xpath_comment_items = \"//div[contains(@class, 'sitetable nestedlisting')]/div[contains(@class, 'comment')]//div[contains(@class, 'md')]/p\"\n",
    "            \n",
    "            # direct to the comment page and forward control to the new tab\n",
    "            driver.execute_script(\"window.open('{}','new window')\".format(cmt_url))\n",
    "\n",
    "            allWindows = driver.window_handles\n",
    "\n",
    "            # give control to the new page\n",
    "            driver.switch_to.window(allWindows[len(allWindows)-1])\n",
    "\n",
    "            #print('\\n-- Windows:', allWindows)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            try:\n",
    "                comments = driver.find_elements(\"xpath\",xpath_comment_items)\n",
    "            except NosuchElementException:\n",
    "                comments = []\n",
    "\n",
    "            comments = [each.text for each in comments if not each.text == \"\"]\n",
    "\n",
    "            #print('/n-- ',post_id, title, title_url, datetime, scores,no_of_cmts, content, cmt_url, comments) \n",
    "\n",
    "            driver.switch_to.window(allWindows[0])\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "            one_instance = {\n",
    "                'p_id': post_id,\n",
    "                'title': title,\n",
    "                'p_url':title_url,\n",
    "                'domain':domain,\n",
    "                'datetime': datetime,\n",
    "                'scores': scores,\n",
    "                'no_of_cmts': no_of_cmts,\n",
    "                'article': content,\n",
    "                'c_url': cmt_url,\n",
    "                'comments': comments\n",
    "            }\n",
    "            out.append(one_instance)\n",
    "            \n",
    "            noOfDocs = noOfDocs + 1\n",
    "            print('\\n-- {} no of records have collected.'.format(noOfDocs))\n",
    "            \n",
    "        # click next to go\n",
    "        xpath_next = \"//div[contains(@class, 'nav-buttons')]//a[contains(text(), 'next')]\"\n",
    "        # Wait for initialize, in seconds\n",
    "        try:\n",
    "            clickToGo(driver, xpath_next)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    return {\"data\":out}\n",
    "\n",
    "'''\n",
    "\n",
    "Input : Xpath for the dropdown list \n",
    "Output: Xpath for the choices in the dropdown\n",
    "\n",
    "'''\n",
    "def getNewsContentByArticle(Article, url):\n",
    "    # get content \n",
    "    try:\n",
    "        content = Article(url)\n",
    "        content.download()\n",
    "        content.parse()\n",
    "        content = content.text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        content = \"\"\n",
    "    return content\n",
    "\n",
    "def getNewsContentByGoogle(title):\n",
    "    \n",
    "    try:\n",
    "        from googlesearch import search\n",
    "    except ImportError:\n",
    "        print(\"No module named 'google' found\")\n",
    "        \n",
    "    channels = [\"channelnewsasia\", \"straitstime\",\"todayonline\"]\n",
    "    \n",
    "    # to search\n",
    "    query = \"news:\" + title\n",
    " \n",
    "    content, domain, url = \"\", \"\", \"\"\n",
    "    \n",
    "    for j in search(query, tld=\"co.in\", num=10, stop=10, pause=2):\n",
    "        url = j\n",
    "        \n",
    "        domain = urlparse(j).netloc\n",
    "        \n",
    "        isIn = [True for c in channels if c in domain]\n",
    "        \n",
    "        content = getNewsContentByArticle(Article,j)\n",
    "        \n",
    "        if not isIn == []:\n",
    "            break\n",
    "    \n",
    "    return {'content':content, 'domain':domain,'url':url}\n",
    "        \n",
    "\n",
    "def getTableItems(driver, xpath_items):\n",
    "    try:\n",
    "        items = driver.find_elements(\"xpath\", xpath_items)\n",
    "    except:\n",
    "        items = []\n",
    "        pass\n",
    "    return items\n",
    "\n",
    "def getDropdownChoices(driver, xpath_dropdown, xpath_choices):\n",
    "    # Wait for initialize, in seconds\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    dropdown = wait.until(EC.visibility_of_element_located((By.XPATH, xpath_dropdown)))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    dropdown.click()\n",
    "    \n",
    "    #2. find the choices on the list\n",
    "    try:\n",
    "        dropdown = driver.find_elements(\"xpath\",xpath_choices)\n",
    "    except ElementClickInterceptedException:\n",
    "        print('\\n-- No dropdown list found --')\n",
    "        pass\n",
    "    \n",
    "    return dropdown\n",
    "\n",
    "def getChildElement(node, xpath):\n",
    "    \n",
    "    xpath = \".//descendant-or-self::\" + xpath\n",
    "    \n",
    "    try:\n",
    "        child_node = node.find_element(\"xpath\", xpath)\n",
    "    except NoSuchElementException:\n",
    "        print(\"\\n-- Unable to find the child element\")\n",
    "        raise\n",
    "        \n",
    "    return child_node\n",
    "\n",
    "\n",
    "def clickToGo(driver, xpath):\n",
    "    try:\n",
    "        button = driver.find_element(\"xpath\",xpath)\n",
    "        button.click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        print('\\n-- No element {} found --'.format(xpath))\n",
    "        raise\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b848d963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liux5\\Documents\\Project 3 - DSTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-3b1810461514>:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=(str(ROOT_DIR)+\"/chromedriver\"), options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- 1 no of records have collected.\n",
      "\n",
      "-- 2 no of records have collected.\n",
      "\n",
      "-- 3 no of records have collected.\n",
      "\n",
      "-- 4 no of records have collected.\n",
      "\n",
      "-- 5 no of records have collected.\n",
      "\n",
      "-- 6 no of records have collected.\n",
      "\n",
      "-- 7 no of records have collected.\n",
      "\n",
      "-- 8 no of records have collected.\n",
      "\n",
      "-- 9 no of records have collected.\n",
      "\n",
      "-- 10 no of records have collected.\n",
      "\n",
      "-- 11 no of records have collected.\n",
      "\n",
      "-- 12 no of records have collected.\n",
      "\n",
      "-- 13 no of records have collected.\n",
      "\n",
      "-- 14 no of records have collected.\n",
      "\n",
      "-- 15 no of records have collected.\n",
      "\n",
      "-- 16 no of records have collected.\n",
      "\n",
      "-- 17 no of records have collected.\n",
      "Article `download()` failed with HTTPSConnectionPool(host='www.reddit.com', port=443): Read timed out. on URL https://www.reddit.com/r/singapore/comments/ttb2hr/all_clear/\n",
      "\n",
      "-- 18 no of records have collected.\n",
      "\n",
      "-- 19 no of records have collected.\n",
      "\n",
      "-- 20 no of records have collected.\n",
      "\n",
      "-- 21 no of records have collected.\n",
      "\n",
      "-- 22 no of records have collected.\n",
      "\n",
      "-- 23 no of records have collected.\n",
      "\n",
      "-- 24 no of records have collected.\n",
      "\n",
      "-- 25 no of records have collected.\n",
      "\n",
      "-- 26 no of records have collected.\n",
      "\n",
      "-- 27 no of records have collected.\n",
      "\n",
      "-- 28 no of records have collected.\n",
      "\n",
      "-- 29 no of records have collected.\n",
      "Article `download()` failed with HTTPSConnectionPool(host='www.asiaone.com', port=443): Read timed out. (read timeout=7) on URL https://www.asiaone.com/singapore/why-not-number-1-singapores-27th-position-world-happiness-report-draws-mixed-reactions\n",
      "Article `download()` failed with 403 Client Error: Forbidden for url: https://www.nst.com.my/news/nation/2022/03/781349/malaysia-happier-china-not-happy-singapore on URL https://www.nst.com.my/news/nation/2022/03/781349/malaysia-happier-china-not-happy-singapore\n",
      "\n",
      "-- 30 no of records have collected.\n",
      "\n",
      "-- 31 no of records have collected.\n",
      "\n",
      "-- 32 no of records have collected.\n",
      "\n",
      "-- 33 no of records have collected.\n",
      "\n",
      "-- 34 no of records have collected.\n",
      "\n",
      "-- 35 no of records have collected.\n",
      "\n",
      "-- 36 no of records have collected.\n",
      "\n",
      "-- 37 no of records have collected.\n",
      "\n",
      "-- 38 no of records have collected.\n",
      "\n",
      "-- 39 no of records have collected.\n",
      "\n",
      "-- 40 no of records have collected.\n",
      "\n",
      "-- 41 no of records have collected.\n",
      "\n",
      "-- 42 no of records have collected.\n",
      "\n",
      "-- 43 no of records have collected.\n",
      "\n",
      "-- 44 no of records have collected.\n",
      "\n",
      "-- 45 no of records have collected.\n",
      "\n",
      "-- 46 no of records have collected.\n",
      "\n",
      "-- 47 no of records have collected.\n",
      "\n",
      "-- 48 no of records have collected.\n",
      "\n",
      "-- 49 no of records have collected.\n",
      "\n",
      "-- 50 no of records have collected.\n",
      "\n",
      "-- 51 no of records have collected.\n",
      "\n",
      "-- 52 no of records have collected.\n",
      "\n",
      "-- 53 no of records have collected.\n",
      "\n",
      "-- 54 no of records have collected.\n",
      "\n",
      "-- 55 no of records have collected.\n",
      "\n",
      "-- 56 no of records have collected.\n",
      "\n",
      "-- 57 no of records have collected.\n",
      "Article `download()` failed with HTTPSConnectionPool(host='www.reddit.com', port=443): Read timed out. on URL https://www.reddit.com/r/Indiana/comments/thhafm/were_number_1_indiana_has_the_most_polluted/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1213: UnknownTimezoneWarning: tzname PST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- 58 no of records have collected.\n",
      "\n",
      "-- 59 no of records have collected.\n",
      "\n",
      "-- 60 no of records have collected.\n",
      "\n",
      "-- 61 no of records have collected.\n",
      "\n",
      "-- 62 no of records have collected.\n",
      "\n",
      "-- 63 no of records have collected.\n",
      "\n",
      "-- 64 no of records have collected.\n",
      "\n",
      "-- 65 no of records have collected.\n",
      "\n",
      "-- 66 no of records have collected.\n",
      "\n",
      "-- 67 no of records have collected.\n",
      "\n",
      "-- 68 no of records have collected.\n",
      "\n",
      "-- 69 no of records have collected.\n",
      "\n",
      "-- 70 no of records have collected.\n",
      "\n",
      "-- 71 no of records have collected.\n",
      "\n",
      "-- 72 no of records have collected.\n",
      "\n",
      "-- 73 no of records have collected.\n",
      "\n",
      "-- 74 no of records have collected.\n",
      "\n",
      "-- 75 no of records have collected.\n",
      "\n",
      "-- 76 no of records have collected.\n",
      "\n",
      "-- 77 no of records have collected.\n",
      "\n",
      "-- 78 no of records have collected.\n",
      "\n",
      "-- 79 no of records have collected.\n",
      "\n",
      "-- 80 no of records have collected.\n",
      "\n",
      "-- 81 no of records have collected.\n",
      "\n",
      "-- 82 no of records have collected.\n",
      "\n",
      "-- 83 no of records have collected.\n",
      "\n",
      "-- 84 no of records have collected.\n",
      "\n",
      "-- 85 no of records have collected.\n",
      "\n",
      "-- 86 no of records have collected.\n",
      "\n",
      "-- 87 no of records have collected.\n",
      "\n",
      "-- 88 no of records have collected.\n",
      "\n",
      "-- 89 no of records have collected.\n",
      "\n",
      "-- 90 no of records have collected.\n",
      "\n",
      "-- 91 no of records have collected.\n",
      "\n",
      "-- 92 no of records have collected.\n",
      "\n",
      "-- 93 no of records have collected.\n",
      "\n",
      "-- 94 no of records have collected.\n",
      "\n",
      "-- 95 no of records have collected.\n",
      "\n",
      "-- 96 no of records have collected.\n",
      "\n",
      "-- 97 no of records have collected.\n",
      "\n",
      "-- 98 no of records have collected.\n",
      "\n",
      "-- 99 no of records have collected.\n",
      "\n",
      "-- 100 no of records have collected.\n",
      "\n",
      "-- 101 no of records have collected.\n",
      "\n",
      "-- 102 no of records have collected.\n",
      "\n",
      "-- 103 no of records have collected.\n",
      "\n",
      "-- 104 no of records have collected.\n",
      "\n",
      "-- 105 no of records have collected.\n",
      "\n",
      "-- 106 no of records have collected.\n",
      "\n",
      "-- 107 no of records have collected.\n",
      "\n",
      "-- 108 no of records have collected.\n",
      "\n",
      "-- 109 no of records have collected.\n",
      "\n",
      "-- 110 no of records have collected.\n",
      "\n",
      "-- 111 no of records have collected.\n",
      "\n",
      "-- 112 no of records have collected.\n",
      "\n",
      "-- 113 no of records have collected.\n",
      "\n",
      "-- 114 no of records have collected.\n",
      "\n",
      "-- 115 no of records have collected.\n",
      "\n",
      "-- 116 no of records have collected.\n",
      "\n",
      "-- 117 no of records have collected.\n",
      "\n",
      "-- 118 no of records have collected.\n",
      "\n",
      "-- 119 no of records have collected.\n",
      "\n",
      "-- 120 no of records have collected.\n",
      "\n",
      "-- 121 no of records have collected.\n",
      "\n",
      "-- 122 no of records have collected.\n",
      "\n",
      "-- 123 no of records have collected.\n",
      "\n",
      "-- 124 no of records have collected.\n",
      "\n",
      "-- 125 no of records have collected.\n",
      "\n",
      "-- 126 no of records have collected.\n",
      "\n",
      "-- 127 no of records have collected.\n",
      "\n",
      "-- 128 no of records have collected.\n",
      "\n",
      "-- 129 no of records have collected.\n",
      "\n",
      "-- 130 no of records have collected.\n",
      "\n",
      "-- 131 no of records have collected.\n",
      "\n",
      "-- 132 no of records have collected.\n",
      "\n",
      "-- 133 no of records have collected.\n",
      "\n",
      "-- 134 no of records have collected.\n",
      "\n",
      "-- 135 no of records have collected.\n",
      "\n",
      "-- 136 no of records have collected.\n",
      "\n",
      "-- 137 no of records have collected.\n",
      "\n",
      "-- 138 no of records have collected.\n",
      "\n",
      "-- 139 no of records have collected.\n",
      "\n",
      "-- 140 no of records have collected.\n",
      "\n",
      "-- 141 no of records have collected.\n",
      "\n",
      "-- 142 no of records have collected.\n",
      "\n",
      "-- 143 no of records have collected.\n",
      "\n",
      "-- 144 no of records have collected.\n",
      "\n",
      "-- 145 no of records have collected.\n",
      "\n",
      "-- 146 no of records have collected.\n",
      "\n",
      "-- 147 no of records have collected.\n",
      "\n",
      "-- 148 no of records have collected.\n",
      "\n",
      "-- 149 no of records have collected.\n",
      "\n",
      "-- 150 no of records have collected.\n",
      "\n",
      "-- 151 no of records have collected.\n",
      "\n",
      "-- 152 no of records have collected.\n",
      "\n",
      "-- 153 no of records have collected.\n",
      "\n",
      "-- 154 no of records have collected.\n",
      "\n",
      "-- 155 no of records have collected.\n",
      "\n",
      "-- 156 no of records have collected.\n",
      "\n",
      "-- 157 no of records have collected.\n",
      "\n",
      "-- 158 no of records have collected.\n",
      "\n",
      "-- 159 no of records have collected.\n",
      "\n",
      "-- 160 no of records have collected.\n",
      "\n",
      "-- 161 no of records have collected.\n",
      "\n",
      "-- 162 no of records have collected.\n",
      "\n",
      "-- 163 no of records have collected.\n",
      "\n",
      "-- 164 no of records have collected.\n",
      "\n",
      "-- 165 no of records have collected.\n",
      "\n",
      "-- 166 no of records have collected.\n",
      "\n",
      "-- 167 no of records have collected.\n",
      "\n",
      "-- 168 no of records have collected.\n",
      "\n",
      "-- 169 no of records have collected.\n",
      "\n",
      "-- 170 no of records have collected.\n",
      "\n",
      "-- 171 no of records have collected.\n",
      "\n",
      "-- 172 no of records have collected.\n",
      "\n",
      "-- 173 no of records have collected.\n",
      "\n",
      "-- 174 no of records have collected.\n",
      "\n",
      "-- 175 no of records have collected.\n",
      "\n",
      "-- 176 no of records have collected.\n",
      "\n",
      "-- 177 no of records have collected.\n",
      "\n",
      "-- 178 no of records have collected.\n",
      "\n",
      "-- 179 no of records have collected.\n",
      "\n",
      "-- 180 no of records have collected.\n",
      "\n",
      "-- 181 no of records have collected.\n",
      "Article `download()` failed with 403 Client Error: Forbidden for url: https://www.news.com.au/national/nsw-act/news/floodaffected-locals-confused-as-singapore-air-force-helicopters-arrive-in-nsw-and-queensland/news-story/3559edf7e179bcc6c9db6ed8d7dd9eb7 on URL https://www.news.com.au/national/nsw-act/news/floodaffected-locals-confused-as-singapore-air-force-helicopters-arrive-in-nsw-and-queensland/news-story/3559edf7e179bcc6c9db6ed8d7dd9eb7\n",
      "Article `download()` failed with 412 Client Error: Precondition Failed for url: https://content.api.news/v3/images/bin/1c5d2d584aa705be312067b6396c0e08?sa=X&ved=2ahUKEwiM-7jTw_L2AhXM4jgGHXSfA9gQ_B16BAgGEAI on URL https://content.api.news/v3/images/bin/1c5d2d584aa705be312067b6396c0e08?sa=X&ved=2ahUKEwiM-7jTw_L2AhXM4jgGHXSfA9gQ_B16BAgGEAI\n",
      "Article `download()` failed with 403 Client Error: Forbidden for url: https://www.news.com.au/national/nsw-act/news/floodaffected-locals-confused-as-singapore-air-force-helicopters-arrive-in-nsw-and-queensland/news-story/3559edf7e179bcc6c9db6ed8d7dd9eb7 on URL https://www.news.com.au/national/nsw-act/news/floodaffected-locals-confused-as-singapore-air-force-helicopters-arrive-in-nsw-and-queensland/news-story/3559edf7e179bcc6c9db6ed8d7dd9eb7\n",
      "Article `download()` failed with HTTPSConnectionPool(host='www.mindef.gov.sg', port=443): Max retries exceeded with url: /web/portal/mindef/news-and-events/latest-releases/article-detail/2022/March/08mar22_nr2 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000015D10F124F0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')) on URL https://www.mindef.gov.sg/web/portal/mindef/news-and-events/latest-releases/article-detail/2022/March/08mar22_nr2\n",
      "\n",
      "-- 182 no of records have collected.\n",
      "\n",
      "-- 183 no of records have collected.\n",
      "\n",
      "-- 184 no of records have collected.\n",
      "\n",
      "-- 185 no of records have collected.\n",
      "\n",
      "-- 186 no of records have collected.\n",
      "\n",
      "-- 187 no of records have collected.\n",
      "\n",
      "-- 188 no of records have collected.\n",
      "\n",
      "-- 189 no of records have collected.\n",
      "\n",
      "-- 190 no of records have collected.\n",
      "\n",
      "-- 191 no of records have collected.\n",
      "\n",
      "-- 192 no of records have collected.\n",
      "\n",
      "-- 193 no of records have collected.\n",
      "\n",
      "-- 194 no of records have collected.\n",
      "\n",
      "-- 195 no of records have collected.\n",
      "\n",
      "-- 196 no of records have collected.\n",
      "\n",
      "-- 197 no of records have collected.\n",
      "\n",
      "-- 198 no of records have collected.\n",
      "\n",
      "-- 199 no of records have collected.\n",
      "\n",
      "-- 200 no of records have collected.\n",
      "\n",
      "-- 201 no of records have collected.\n",
      "\n",
      "-- 202 no of records have collected.\n",
      "\n",
      "-- 203 no of records have collected.\n",
      "\n",
      "-- 204 no of records have collected.\n",
      "\n",
      "-- 205 no of records have collected.\n",
      "\n",
      "-- 206 no of records have collected.\n",
      "\n",
      "-- 207 no of records have collected.\n",
      "\n",
      "-- 208 no of records have collected.\n",
      "\n",
      "-- 209 no of records have collected.\n",
      "\n",
      "-- 210 no of records have collected.\n",
      "\n",
      "-- 211 no of records have collected.\n",
      "\n",
      "-- 212 no of records have collected.\n",
      "\n",
      "-- 213 no of records have collected.\n",
      "\n",
      "-- 214 no of records have collected.\n",
      "\n",
      "-- 215 no of records have collected.\n",
      "\n",
      "-- 216 no of records have collected.\n",
      "\n",
      "-- 217 no of records have collected.\n",
      "\n",
      "-- 218 no of records have collected.\n",
      "\n",
      "-- 219 no of records have collected.\n",
      "\n",
      "-- 220 no of records have collected.\n",
      "\n",
      "-- 221 no of records have collected.\n",
      "\n",
      "-- 222 no of records have collected.\n",
      "\n",
      "-- 223 no of records have collected.\n",
      "\n",
      "-- 224 no of records have collected.\n",
      "\n",
      "-- 225 no of records have collected.\n",
      "\n",
      "-- 226 no of records have collected.\n",
      "\n",
      "-- 227 no of records have collected.\n",
      "\n",
      "-- 228 no of records have collected.\n",
      "\n",
      "-- 229 no of records have collected.\n",
      "\n",
      "-- 230 no of records have collected.\n",
      "\n",
      "-- 231 no of records have collected.\n",
      "\n",
      "-- 232 no of records have collected.\n",
      "\n",
      "-- 233 no of records have collected.\n",
      "\n",
      "-- 234 no of records have collected.\n",
      "\n",
      "-- 235 no of records have collected.\n",
      "\n",
      "-- 236 no of records have collected.\n",
      "\n",
      "-- 237 no of records have collected.\n",
      "\n",
      "-- 238 no of records have collected.\n",
      "\n",
      "-- 239 no of records have collected.\n",
      "\n",
      "-- 240 no of records have collected.\n",
      "\n",
      "-- 241 no of records have collected.\n",
      "\n",
      "-- 242 no of records have collected.\n",
      "\n",
      "-- 243 no of records have collected.\n",
      "\n",
      "-- 244 no of records have collected.\n",
      "\n",
      "-- 245 no of records have collected.\n",
      "\n",
      "-- 246 no of records have collected.\n",
      "\n",
      "-- 247 no of records have collected.\n",
      "\n",
      "-- 248 no of records have collected.\n",
      "\n",
      "-- 249 no of records have collected.\n",
      "\n",
      "-- 250 no of records have collected.\n",
      "\n",
      "-- 251 no of records have collected.\n",
      "\n",
      "-- 252 no of records have collected.\n",
      "\n",
      "-- 253 no of records have collected.\n",
      "\n",
      "-- 254 no of records have collected.\n",
      "\n",
      "-- 255 no of records have collected.\n",
      "\n",
      "-- 256 no of records have collected.\n",
      "\n",
      "-- 257 no of records have collected.\n",
      "\n",
      "-- 258 no of records have collected.\n",
      "\n",
      "-- 259 no of records have collected.\n",
      "\n",
      "-- 260 no of records have collected.\n",
      "\n",
      "-- 261 no of records have collected.\n",
      "\n",
      "-- 262 no of records have collected.\n",
      "\n",
      "-- 263 no of records have collected.\n",
      "\n",
      "-- 264 no of records have collected.\n",
      "\n",
      "-- 265 no of records have collected.\n",
      "\n",
      "-- 266 no of records have collected.\n",
      "\n",
      "-- 267 no of records have collected.\n",
      "\n",
      "-- 268 no of records have collected.\n",
      "\n",
      "-- 269 no of records have collected.\n",
      "\n",
      "-- 270 no of records have collected.\n",
      "\n",
      "-- 271 no of records have collected.\n",
      "\n",
      "-- 272 no of records have collected.\n",
      "\n",
      "-- 273 no of records have collected.\n",
      "\n",
      "-- 274 no of records have collected.\n",
      "\n",
      "-- 275 no of records have collected.\n",
      "\n",
      "-- 276 no of records have collected.\n",
      "\n",
      "-- 277 no of records have collected.\n",
      "\n",
      "-- 278 no of records have collected.\n",
      "\n",
      "-- 279 no of records have collected.\n",
      "\n",
      "-- 280 no of records have collected.\n",
      "\n",
      "-- 281 no of records have collected.\n",
      "\n",
      "-- 282 no of records have collected.\n",
      "\n",
      "-- 283 no of records have collected.\n",
      "\n",
      "-- 284 no of records have collected.\n",
      "\n",
      "-- 285 no of records have collected.\n",
      "\n",
      "-- 286 no of records have collected.\n",
      "\n",
      "-- 287 no of records have collected.\n",
      "\n",
      "-- 288 no of records have collected.\n",
      "Article `download()` failed with 403 Client Error: Forbidden for url: https://blog.sgtrains.com/2022/03/new-c851e-ccl-train-arrive/ on URL https://blog.sgtrains.com/2022/03/new-c851e-ccl-train-arrive/\n",
      "\n",
      "-- 289 no of records have collected.\n",
      "\n",
      "-- 290 no of records have collected.\n",
      "\n",
      "-- 291 no of records have collected.\n",
      "\n",
      "-- 292 no of records have collected.\n",
      "\n",
      "-- 293 no of records have collected.\n",
      "\n",
      "-- 294 no of records have collected.\n",
      "\n",
      "-- 295 no of records have collected.\n",
      "\n",
      "-- 296 no of records have collected.\n",
      "\n",
      "-- 297 no of records have collected.\n",
      "\n",
      "-- 298 no of records have collected.\n",
      "\n",
      "-- 299 no of records have collected.\n",
      "\n",
      "-- 300 no of records have collected.\n",
      "\n",
      "-- 301 no of records have collected.\n",
      "\n",
      "-- 302 no of records have collected.\n",
      "\n",
      "-- 303 no of records have collected.\n",
      "\n",
      "-- 304 no of records have collected.\n",
      "\n",
      "-- 305 no of records have collected.\n",
      "\n",
      "-- 306 no of records have collected.\n",
      "\n",
      "-- 307 no of records have collected.\n",
      "\n",
      "-- 308 no of records have collected.\n",
      "\n",
      "-- 309 no of records have collected.\n",
      "\n",
      "-- 310 no of records have collected.\n",
      "\n",
      "-- 311 no of records have collected.\n",
      "\n",
      "-- 312 no of records have collected.\n",
      "\n",
      "-- 313 no of records have collected.\n",
      "\n",
      "-- 314 no of records have collected.\n",
      "\n",
      "-- 315 no of records have collected.\n",
      "\n",
      "-- 316 no of records have collected.\n",
      "\n",
      "-- 317 no of records have collected.\n",
      "\n",
      "-- 318 no of records have collected.\n",
      "\n",
      "-- 319 no of records have collected.\n",
      "\n",
      "-- 320 no of records have collected.\n",
      "\n",
      "-- 321 no of records have collected.\n",
      "\n",
      "-- 322 no of records have collected.\n",
      "\n",
      "-- 323 no of records have collected.\n",
      "\n",
      "-- 324 no of records have collected.\n",
      "\n",
      "-- 325 no of records have collected.\n",
      "\n",
      "-- 326 no of records have collected.\n",
      "\n",
      "-- 327 no of records have collected.\n",
      "\n",
      "-- 328 no of records have collected.\n",
      "\n",
      "-- 329 no of records have collected.\n",
      "\n",
      "-- 330 no of records have collected.\n",
      "\n",
      "-- 331 no of records have collected.\n",
      "\n",
      "-- 332 no of records have collected.\n",
      "\n",
      "-- 333 no of records have collected.\n",
      "\n",
      "-- 334 no of records have collected.\n",
      "\n",
      "-- 335 no of records have collected.\n",
      "\n",
      "-- 336 no of records have collected.\n",
      "\n",
      "-- 337 no of records have collected.\n",
      "\n",
      "-- 338 no of records have collected.\n",
      "\n",
      "-- 339 no of records have collected.\n",
      "\n",
      "-- 340 no of records have collected.\n",
      "\n",
      "-- 341 no of records have collected.\n",
      "\n",
      "-- 342 no of records have collected.\n",
      "\n",
      "-- 343 no of records have collected.\n",
      "\n",
      "-- 344 no of records have collected.\n",
      "\n",
      "-- 345 no of records have collected.\n",
      "\n",
      "-- 346 no of records have collected.\n",
      "\n",
      "-- 347 no of records have collected.\n",
      "\n",
      "-- 348 no of records have collected.\n",
      "\n",
      "-- 349 no of records have collected.\n",
      "\n",
      "-- 350 no of records have collected.\n",
      "\n",
      "-- 351 no of records have collected.\n",
      "\n",
      "-- 352 no of records have collected.\n",
      "\n",
      "-- 353 no of records have collected.\n",
      "\n",
      "-- 354 no of records have collected.\n",
      "\n",
      "-- 355 no of records have collected.\n",
      "\n",
      "-- 356 no of records have collected.\n",
      "\n",
      "-- 357 no of records have collected.\n",
      "\n",
      "-- 358 no of records have collected.\n",
      "\n",
      "-- 359 no of records have collected.\n",
      "\n",
      "-- 360 no of records have collected.\n",
      "\n",
      "-- 361 no of records have collected.\n",
      "\n",
      "-- 362 no of records have collected.\n",
      "\n",
      "-- 363 no of records have collected.\n",
      "\n",
      "-- 364 no of records have collected.\n",
      "\n",
      "-- 365 no of records have collected.\n",
      "\n",
      "-- 366 no of records have collected.\n",
      "\n",
      "-- 367 no of records have collected.\n",
      "\n",
      "-- 368 no of records have collected.\n",
      "\n",
      "-- 369 no of records have collected.\n",
      "\n",
      "-- 370 no of records have collected.\n",
      "\n",
      "-- 371 no of records have collected.\n",
      "\n",
      "-- 372 no of records have collected.\n",
      "\n",
      "-- 373 no of records have collected.\n",
      "\n",
      "-- 374 no of records have collected.\n",
      "\n",
      "-- 375 no of records have collected.\n",
      "\n",
      "-- 376 no of records have collected.\n",
      "\n",
      "-- 377 no of records have collected.\n",
      "\n",
      "-- 378 no of records have collected.\n",
      "\n",
      "-- 379 no of records have collected.\n",
      "\n",
      "-- 380 no of records have collected.\n",
      "\n",
      "-- 381 no of records have collected.\n",
      "\n",
      "-- 382 no of records have collected.\n",
      "\n",
      "-- 383 no of records have collected.\n",
      "\n",
      "-- 384 no of records have collected.\n",
      "\n",
      "-- 385 no of records have collected.\n",
      "\n",
      "-- 386 no of records have collected.\n",
      "\n",
      "-- 387 no of records have collected.\n",
      "\n",
      "-- 388 no of records have collected.\n",
      "\n",
      "-- 389 no of records have collected.\n",
      "\n",
      "-- 390 no of records have collected.\n",
      "\n",
      "-- 391 no of records have collected.\n",
      "\n",
      "-- 392 no of records have collected.\n",
      "\n",
      "-- 393 no of records have collected.\n",
      "\n",
      "-- 394 no of records have collected.\n",
      "\n",
      "-- 395 no of records have collected.\n",
      "\n",
      "-- 396 no of records have collected.\n",
      "\n",
      "-- 397 no of records have collected.\n",
      "\n",
      "-- 398 no of records have collected.\n",
      "\n",
      "-- 399 no of records have collected.\n",
      "\n",
      "-- 400 no of records have collected.\n",
      "\n",
      "-- 401 no of records have collected.\n",
      "\n",
      "-- 402 no of records have collected.\n",
      "\n",
      "-- 403 no of records have collected.\n",
      "\n",
      "-- 404 no of records have collected.\n",
      "\n",
      "-- 405 no of records have collected.\n",
      "\n",
      "-- 406 no of records have collected.\n",
      "\n",
      "-- 407 no of records have collected.\n",
      "\n",
      "-- 408 no of records have collected.\n",
      "\n",
      "-- 409 no of records have collected.\n",
      "\n",
      "-- 410 no of records have collected.\n",
      "\n",
      "-- 411 no of records have collected.\n",
      "\n",
      "-- 412 no of records have collected.\n",
      "\n",
      "-- 413 no of records have collected.\n",
      "\n",
      "-- 414 no of records have collected.\n",
      "\n",
      "-- 415 no of records have collected.\n",
      "\n",
      "-- 416 no of records have collected.\n",
      "\n",
      "-- 417 no of records have collected.\n",
      "\n",
      "-- 418 no of records have collected.\n",
      "\n",
      "-- 419 no of records have collected.\n",
      "\n",
      "-- 420 no of records have collected.\n",
      "\n",
      "-- 421 no of records have collected.\n",
      "\n",
      "-- 422 no of records have collected.\n",
      "\n",
      "-- 423 no of records have collected.\n",
      "\n",
      "-- 424 no of records have collected.\n",
      "\n",
      "-- 425 no of records have collected.\n",
      "\n",
      "-- 426 no of records have collected.\n",
      "\n",
      "-- 427 no of records have collected.\n",
      "\n",
      "-- 428 no of records have collected.\n",
      "\n",
      "-- 429 no of records have collected.\n",
      "\n",
      "-- 430 no of records have collected.\n",
      "\n",
      "-- 431 no of records have collected.\n",
      "\n",
      "-- 432 no of records have collected.\n",
      "\n",
      "-- 433 no of records have collected.\n",
      "\n",
      "-- 434 no of records have collected.\n",
      "\n",
      "-- 435 no of records have collected.\n",
      "\n",
      "-- 436 no of records have collected.\n",
      "\n",
      "-- 437 no of records have collected.\n",
      "\n",
      "-- 438 no of records have collected.\n",
      "\n",
      "-- 439 no of records have collected.\n",
      "\n",
      "-- 440 no of records have collected.\n",
      "\n",
      "-- 441 no of records have collected.\n",
      "\n",
      "-- 442 no of records have collected.\n",
      "\n",
      "-- 443 no of records have collected.\n",
      "\n",
      "-- 444 no of records have collected.\n",
      "\n",
      "-- 445 no of records have collected.\n",
      "\n",
      "-- 446 no of records have collected.\n",
      "\n",
      "-- 447 no of records have collected.\n",
      "\n",
      "-- 448 no of records have collected.\n",
      "\n",
      "-- 449 no of records have collected.\n",
      "\n",
      "-- 450 no of records have collected.\n",
      "\n",
      "-- 451 no of records have collected.\n",
      "\n",
      "-- 452 no of records have collected.\n",
      "\n",
      "-- 453 no of records have collected.\n",
      "\n",
      "-- 454 no of records have collected.\n",
      "\n",
      "-- 455 no of records have collected.\n",
      "\n",
      "-- 456 no of records have collected.\n",
      "\n",
      "-- 457 no of records have collected.\n",
      "\n",
      "-- 458 no of records have collected.\n",
      "\n",
      "-- 459 no of records have collected.\n",
      "\n",
      "-- 460 no of records have collected.\n",
      "\n",
      "-- 461 no of records have collected.\n",
      "\n",
      "-- 462 no of records have collected.\n",
      "\n",
      "-- 463 no of records have collected.\n",
      "\n",
      "-- 464 no of records have collected.\n",
      "\n",
      "-- 465 no of records have collected.\n",
      "\n",
      "-- 466 no of records have collected.\n",
      "\n",
      "-- 467 no of records have collected.\n",
      "\n",
      "-- 468 no of records have collected.\n",
      "\n",
      "-- 469 no of records have collected.\n",
      "\n",
      "-- 470 no of records have collected.\n",
      "\n",
      "-- 471 no of records have collected.\n",
      "\n",
      "-- 472 no of records have collected.\n",
      "\n",
      "-- 473 no of records have collected.\n",
      "\n",
      "-- 474 no of records have collected.\n",
      "\n",
      "-- 475 no of records have collected.\n",
      "\n",
      "-- 476 no of records have collected.\n",
      "\n",
      "-- 477 no of records have collected.\n",
      "\n",
      "-- 478 no of records have collected.\n",
      "\n",
      "-- 479 no of records have collected.\n",
      "\n",
      "-- 480 no of records have collected.\n",
      "\n",
      "-- 481 no of records have collected.\n",
      "\n",
      "-- 482 no of records have collected.\n",
      "\n",
      "-- 483 no of records have collected.\n",
      "\n",
      "-- 484 no of records have collected.\n",
      "\n",
      "-- 485 no of records have collected.\n",
      "\n",
      "-- 486 no of records have collected.\n",
      "\n",
      "-- 487 no of records have collected.\n",
      "\n",
      "-- 488 no of records have collected.\n",
      "\n",
      "-- 489 no of records have collected.\n",
      "\n",
      "-- 490 no of records have collected.\n",
      "\n",
      "-- 491 no of records have collected.\n",
      "\n",
      "-- 492 no of records have collected.\n",
      "\n",
      "-- 493 no of records have collected.\n",
      "\n",
      "-- 494 no of records have collected.\n",
      "\n",
      "-- 495 no of records have collected.\n",
      "\n",
      "-- 496 no of records have collected.\n",
      "\n",
      "-- 497 no of records have collected.\n",
      "\n",
      "-- 498 no of records have collected.\n",
      "\n",
      "-- 499 no of records have collected.\n",
      "\n",
      "-- 500 no of records have collected.\n",
      "\n",
      "-- 501 no of records have collected.\n",
      "\n",
      "-- 502 no of records have collected.\n",
      "\n",
      "-- 503 no of records have collected.\n",
      "\n",
      "-- 504 no of records have collected.\n",
      "\n",
      "-- 505 no of records have collected.\n",
      "\n",
      "-- 506 no of records have collected.\n",
      "\n",
      "-- 507 no of records have collected.\n",
      "\n",
      "-- 508 no of records have collected.\n",
      "\n",
      "-- 509 no of records have collected.\n",
      "\n",
      "-- 510 no of records have collected.\n",
      "\n",
      "-- 511 no of records have collected.\n",
      "\n",
      "-- 512 no of records have collected.\n",
      "\n",
      "-- 513 no of records have collected.\n",
      "\n",
      "-- 514 no of records have collected.\n",
      "\n",
      "-- 515 no of records have collected.\n",
      "\n",
      "-- 516 no of records have collected.\n",
      "\n",
      "-- 517 no of records have collected.\n",
      "\n",
      "-- 518 no of records have collected.\n",
      "\n",
      "-- 519 no of records have collected.\n",
      "\n",
      "-- 520 no of records have collected.\n",
      "\n",
      "-- 521 no of records have collected.\n",
      "\n",
      "-- 522 no of records have collected.\n",
      "\n",
      "-- 523 no of records have collected.\n",
      "\n",
      "-- 524 no of records have collected.\n",
      "\n",
      "-- 525 no of records have collected.\n",
      "\n",
      "-- 526 no of records have collected.\n",
      "\n",
      "-- 527 no of records have collected.\n",
      "\n",
      "-- 528 no of records have collected.\n",
      "\n",
      "-- 529 no of records have collected.\n",
      "\n",
      "-- 530 no of records have collected.\n",
      "\n",
      "-- 531 no of records have collected.\n",
      "\n",
      "-- 532 no of records have collected.\n",
      "\n",
      "-- 533 no of records have collected.\n",
      "\n",
      "-- 534 no of records have collected.\n",
      "\n",
      "-- 535 no of records have collected.\n",
      "\n",
      "-- 536 no of records have collected.\n",
      "\n",
      "-- 537 no of records have collected.\n",
      "\n",
      "-- 538 no of records have collected.\n",
      "\n",
      "-- 539 no of records have collected.\n",
      "\n",
      "-- 540 no of records have collected.\n",
      "\n",
      "-- 541 no of records have collected.\n",
      "\n",
      "-- 542 no of records have collected.\n",
      "\n",
      "-- 543 no of records have collected.\n",
      "\n",
      "-- 544 no of records have collected.\n",
      "\n",
      "-- 545 no of records have collected.\n",
      "\n",
      "-- 546 no of records have collected.\n",
      "\n",
      "-- 547 no of records have collected.\n",
      "\n",
      "-- No element //div[contains(@class, 'nav-buttons')]//a[contains(text(), 'next')] found --\n"
     ]
    }
   ],
   "source": [
    "items = RedditSearch(url,\"past month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b8063b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reddit-03.json', 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(items , output_file ,indent = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0cf6db",
   "metadata": {},
   "source": [
    "# testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8e179cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGAPORE: Along Armenian Street lies a nondescript grey and white colonial building, which used to be a power station between the late-1920s and 1970s. \n",
      "The 1,630-sqm three-storey centre, which was converted from a disused power station, houses a black box theatre, studios and an art gallery. \n",
      "However, after about three decades of being a mainstay in the arts scene, The Substation will vacate its premise in July, with the National Arts Council (NAC) taking back the building for renovation works. \n",
      "The NAC had said that the building is a conserved property and there is a need for a major upgrading to preserve its structural integrity. The Substation is considering some alternative venues, including Goodman Arts Centre in Mountbatten and Aliwal Arts Centre in Kampong Glam but has yet to finalise its decision. \n",
      "From punk rockers to filmmakers, The Substation was a melting pot that allowed artists of different genres to seek out collaborators and make lifelong friends.  \n",
      "“There was a hole where we crept through. It was smelly and dusty. It smelled like urine and it was covered in cobwebs… and he said this can be an arts centre,” recounted Mr Tay, 80.\n",
      "For example, while the architect wanted a variety of colours to feature in the black box, Mr Kuo wanted it to be just black to avoid drawing attention to the space’s features. \n",
      "Drama Box, headed by drama stalwart and former Nominated Member of Parliament Kok Heng Leun, was founded in 1990 following a gathering of former drama practitioners from the National University of Singapore at The Substation’s garden. \n",
      "The group later went on to hold its first production at the arts centre’s black box the following year. \n",
      "The first play to be staged at the black box was The Necessary Stage’s Those Who Can’t, Teach. \n",
      "Before that, we never had a regular venue to perform at. It was always an ad hoc gig or event at a festival. So when The Substation came out, it was like ‘wow’. \n",
      "He returned to The Substation regularly, at least once a month, and gradually found himself actively immersed in other aspects of the centre. \n",
      "Mr Chia Aik Beng, a 53-year-old senior director in an advertising firm who used to sell his illustrations at The Substation’s weekend flea market in the 90s, said that the centre welcomed a good mix of ordinary people and those with artistic backgrounds. \n",
      "“The whole place is cosy and everyone mingled with each other at the flea market and we sat at each other’s table and chit-chatted,” recalled Mr Chia, who is also a well-known photographer. \n",
      "One of these was The Necessary Stage, which was founded in 1987 and headed by Mr Tan who received the Cultural Medallion in 2014. He said that he was excited by the possibilities offered by The Substation’s black box, a new theatre concept to him at that time.\n",
      "Unlike the conventional spaces such as the Drama Centre where The Necessary Stage was initially staging its works, the black box space — which provides flexibility on where the audience and cast can be situated — allowed the drama troupe to experiment with its works, said Mr Tan.\n",
      "For theatre veteran Ang Gey Pin, 55, The Substation has been integral to her growth as an artist. Her first solo work was at The Substation in 1992 which featured a performance entirely in Hokkien. At that time, it was rare for entire shows to feature dialect, said Ms Ang.\n",
      "Mr Tan said The Substation continues to be a safe space for the newer generation or even veterans like himself to try their hand at new works without having to worry about putting up polished works.  \n",
      "For example, he is currently directing a performance featuring emerging artists called subTitled 1.0 at The Substation under an initiative called Bridging The Gap, which supports students graduating from theatre institutions by linking them up with established theatre professionals. \n",
      "Despite being a veteran director, he said he is unable to stage such a work during The Necessary Stage’s main season. This is because a production featuring young, emerging artists could fail and miss the key performance indicators (KPI) set by NAC. \n",
      "Failing the KPIs could affect The Necessary Stage’s qualification for grants in future, said Mr Tan. \n",
      "“So this kind of project where we want to link young artists to the industry is ‘high-risk’ and only The Substation will be the venue sponsor for such a project,” he added. \n",
      "Over the last three decades, both the building at 45 Armenian Street and its surroundings have seen many changes. And some of those interviewed by TODAY believe that the magic of The Substation has faded somewhat.  \n",
      "The Substation garden made way for bistro Timbre in 2005, while the coffeeshops in the vicinity made way for an extension of the Singapore Management University and art galleries. The road outside the building was also pedestrianised. \n",
      "Without the usual spaces to gather at, The Substation is no longer what it once was, said some patrons. Coupled with changing programming over the years and the emergence of other performance art spaces such as The Esplanade, this has contributed to fewer people in the arts community visiting The Substation, said some patrons. \n",
      "Mr Chng of The Oddfellows said that smaller venues supporting indie music, such as Home Club which was at Upper Circular Road, also meant that bands relied less on The Substation to host gigs. \n",
      "The Substation building has also aged over the years, noted Mr Isyraf. For instance, it has yet to receive a fresh coat of paint since 2015. \n",
      "“They have to believe in it, and they must be willing to defend it to the very end, no matter what. And if they are able to do it, I think they can survive anywhere,” he said. \n",
      "Mr Sasitharan believes that it takes time for a place to build up a community spirit. \n"
     ]
    }
   ],
   "source": [
    "HEADERS = {\n",
    "        'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36', #Google Chrome user agent header\n",
    "        'hl'        :  'en'\n",
    "    }\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "s.headers.update(HEADERS)\n",
    "\n",
    "'''\n",
    "scrape article content through css selector:\n",
    "    steps: download page -parse xml - \n",
    "\n",
    "'''\n",
    "\n",
    "def getNewsByCSS(article_url):\n",
    "    \n",
    "    article, news_title, category, date, = '', '', '', ''\n",
    "\n",
    "    try:\n",
    "        r = s.get(article_url)\n",
    "        \n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "    except Exception as e:\n",
    "        print('\\n--',e,' for the link:',article_url)\n",
    "    \n",
    "    #print(soup)\n",
    "    try:\n",
    "        news_title = soup.select('h1[class*=\"h1--page-title\"]')[0].get_text().strip()\n",
    "    except Exception as e:\n",
    "        print('\\n--',e,' for title')\n",
    "        \n",
    "    try:\n",
    "        category = soup.select('p[class*=\"content-detail__category\"]')[0].get_text().strip()\n",
    "    except Exception as e:\n",
    "        print('\\n--',e,' for category') \n",
    "    \n",
    "    try:    \n",
    "        date = soup.select('div[class*=\"article-publish\"]')[0].get_text().strip()\n",
    "    except Exception as e:\n",
    "        print('\\n--',e,' for date')\n",
    "    \n",
    "    try:    \n",
    "        #get the article text    \n",
    "        for p_div in soup.select('div[class=\"text\"]>div[class*=\"text-long\"]'):\n",
    "            for paragraph in p_div.find_all('p'):\n",
    "                if paragraph.get_text().find('\\u00A0') != -1:\n",
    "                    print(paragraph.get_text())\n",
    "                    continue\n",
    "                article += paragraph.get_text() + '\\n'\n",
    "        \n",
    "        article = article.strip()\n",
    "    except Exception as e:\n",
    "        print('\\n--',e,' for the link:',article_url)\n",
    "        \n",
    "        # any of the elements cannot be found above return nth\n",
    "    \n",
    "    return {'url': article_url,\n",
    "            'date_publish': date,\n",
    "            'news_title': news_title,\n",
    "            'news_category': category,\n",
    "            'article': article}\n",
    "\n",
    "out = getNewsByCSS(\"https://www.channelnewsasia.com/singapore/the-big-read-substation-power-station-arts-artists-363776\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "879d36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st\n",
    "#url_1 = 'https://www.straitstimes.com/singapore/singapore-ushers-in-2015-with-brilliant-fireworks-display-song-performances'\n",
    "#url_2 = 'https://www.straitstimes.com/singapore/what-makes-you-delicious-to-mozzies' #different html layout\n",
    "#cna\n",
    "#url_1 = \"https://www.channelnewsasia.com/singapore/covid19-coronavirus-measures-vaccination-omicron-dale-fisher-2466416\"\n",
    "#8world\n",
    "url_1 = \"https://www.8world.com/singapore/national-service-registration-1618321\"\n",
    "\n",
    "#zb\n",
    "url_1 = \"https://www.zaobao.com.sg/realtime/singapore/story20220101-1228418\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe35a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "挥别2021年 10个邻里烟火秀照亮新的一年\n",
      "{'url': 'https://www.zaobao.com.sg/realtime/singapore/story20220101-1228418', 'date_publish': '文 / \\n邓玮婷\\n\\n\\n        \\n                  发布 / 2022年1月1日 12:48 AM\\n      \\n  \\n    \\n\\n        \\n                  更新 / 2022年1月1日 12:59 AM', 'news_title': '挥别2021年 10个邻里烟火秀照亮新的一年', 'news_category': '即时\\n\\n\\n\\n新加坡', 'article': '（早报讯）细雨中挥别2021年，烟火光下再起航，新年快乐！\\n午夜零时一到，夜空飘下细雨，礼花弹往天上冲，水中有火，夜中有光，一场视觉飨宴下为2022年开启新篇章。\\n滨海湾跨年倒数活动连续第二年不燃放烟花，不过有10个邻里举办烟花表演，让公众通过线上直播观赏。\\n住在联邦一带的周欣妮（40岁，客服人员）今晚特地带七岁女儿下楼看烟花秀跨年。她受访时说，住在这里超过10年，第一次下楼就能看烟花秀。\\n“烟花就在眼前，心情很兴奋，烟花秀很精彩，真的没想到能这么近距离看到烟花！老公没法和我们一起看烟花，替他可惜了。”\\n“新的一年祝愿大家健康快乐，希望2022年有机会出国游玩。”\\n由于新加坡以谨慎方式恢复社交活动，逐步迈向与冠病共存，人民协会连续第二年把社区跨年倒数活动搬上网，烟花秀也再次走入邻里。10个邻里区包括勿洛、碧山、文礼、波纳维斯达、蔡厝港、后港、三巴旺、淡滨尼、兀兰和景万岸－菜市今晚都呈现了烟花秀，把倒数活动推向高潮。\\n在三巴旺看烟花秀的潘银银（30岁，待业）说：“希望看了今晚的跨年烟花，来年会幸运一点。”'}\n"
     ]
    }
   ],
   "source": [
    "#8world\n",
    "title = 'header[class*=\"article-header\"]'\n",
    "\n",
    "date = 'div[class*=\"field--type-datetime\"]'\n",
    "\n",
    "category = 'ul>li[class*=\"article-header\"]'\n",
    "\n",
    "paragraphs = 'div[class\"text\"] > div[class=\"text-long\"]'\n",
    "\n",
    "#ZB news\n",
    "css_title = 'div[class*=\"article-title\"]'\n",
    "\n",
    "css_date = 'div[class*=\"article-byline\"]'\n",
    "\n",
    "css_category = 'ul[class*=\"breadcrumbs-list\"]'\n",
    "\n",
    "css_paragraphs = 'div[class*=\"article-content-rawhtml\"]'\n",
    "\n",
    "\n",
    "print(scrape_news_By_CSS_Selector(url_1,css_title,css_date,css_category,css_paragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c83064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
